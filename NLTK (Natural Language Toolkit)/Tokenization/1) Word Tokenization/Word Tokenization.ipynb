{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Word Tokenization`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word tokenization is the process of splitting a text into individual words or tokens. It's a fundamental step in natural language processing (NLP) and text analysis tasks. Word tokenization allows the computer to understand and process text at the level of individual words, enabling further analysis such as sentiment analysis, named entity recognition, and topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLTK', 'is', 'a', 'powerful', 'tool', 'for', 'natural', 'language', 'processing', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text data\n",
    "text = \"NLTK is a powerful tool for natural language processing.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Priyal', 'ji', 'is', 'a', 'lord', 'of', 'the', 'my', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text data\n",
    "text = \"Priyal ji is a lord of the my world.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shraddhu', 'ji', 'is', 'a', 'lord', 'of', 'the', 'my', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text data\n",
    "text = \"shraddhu ji is a lord of the my world.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
